{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNamoUSoP2yX1fm5vas5xVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zs856/TensorFlow-Developer-Certificate-in-2023-Zero-to-Mastery/blob/main/Introduction_to_NLP_Fundamentals_in_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be seqeuences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ],
      "metadata": {
        "id": "PTuChcPkrkV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for GPU"
      ],
      "metadata": {
        "id": "3xM8dVftrnvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSbNniMGrrD3",
        "outputId": "1ade6b38-57fa-4c7f-b654-269d7b2aaa5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions"
      ],
      "metadata": {
        "id": "BJjS8LxFr0o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import  unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwO6fPGtry-n",
        "outputId": "4395fcb3-1567-4b51-e06f-aece21067667"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-16 01:24:14--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-16 01:24:14 (58.1 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP\n",
        "dataset (text samples of Tweets labelled as diaster or not diaster).\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ],
      "metadata": {
        "id": "EJ6s7pHRtNE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMkywmQltJ_z",
        "outputId": "8b3ed988-913a-4584-e52c-7470beae5089"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-16 01:24:19--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.122.128, 142.251.167.128, 172.253.63.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.122.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-02-16 01:24:19 (86.1 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way \n",
        "to do so would be to use Python: \n",
        "\n",
        "https://realpython.com/read-write-files-python/\n",
        "\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "\n",
        "So another way to do this is to use pandas..."
      ],
      "metadata": {
        "id": "aFFDbFtyvxqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df= pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YW0S5zNUuMlU",
        "outputId": "b427114e-2e9b-4741-de36-b41fb6ae9e10"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3978aa5f-8d34-4364-a985-4cd3706304e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3978aa5f-8d34-4364-a985-4cd3706304e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3978aa5f-8d34-4364-a985-4cd3706304e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3978aa5f-8d34-4364-a985-4cd3706304e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled= train_df.sample(frac=1,random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c4TwDbYTxH_2",
        "outputId": "a1fff58a-1ee8-4539-e260-61a7c4cafc6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-801dc588-7e25-48e0-8648-c2623b881128\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-801dc588-7e25-48e0-8648-c2623b881128')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-801dc588-7e25-48e0-8648-c2623b881128 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-801dc588-7e25-48e0-8648-c2623b881128');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WSW2QfgtxOV5",
        "outputId": "ad5e97e8-90e8-4bce-e96b-6b54bea01d02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-996efd50-2299-47a2-9aff-ba0832d41c0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-996efd50-2299-47a2-9aff-ba0832d41c0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-996efd50-2299-47a2-9aff-ba0832d41c0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-996efd50-2299-47a2-9aff-ba0832d41c0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1di9LMKx0LZ",
        "outputId": "d90f4dc5-8b99-4670-9338-88b8eb051c9a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gmOZ2kqx_MY",
        "outputId": "cfa51392-e4df-4e46-a4d2-8c6bfd6e9975"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # crate random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\",\"target\"]][random_index: random_index+5].itertuples():\n",
        "  _,text,target = row\n",
        "  print(f\"Target: {target}\",\"real diaster\" if target>0 else \"(not real diaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNFTYhoqyhDm",
        "outputId": "72b40456-f933-46c0-c192-6f3d2bb5ecbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 real diaster\n",
            "Text:\n",
            "Philippines Must Protect Internally Displaced Persons Warns UN Expert http://t.co/xLZWTzgQTC\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 real diaster\n",
            "Text:\n",
            "'Food crematoria' provoke outrage amid crisis famine memories... http://t.co/fABVlvN5MS\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real diaster)\n",
            "Text:\n",
            "#iphone #twist Ultimate #preparedness library: http://t.co/ksgmY0D0Mx Prepare Yourself For Any Catastrophe. Ov http://t.co/MZK0PFogI7\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real diaster)\n",
            "Text:\n",
            "today will be another dualcom with @Im_Razed !!! if you enjoyed yesterdays check out todays at 5 pm easter!!!\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real diaster)\n",
            "Text:\n",
            "Sinking carb consultative assembly plans could subconscious self live straight a leading way of escape: XkDrx\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### split data into training and validation sets"
      ],
      "metadata": {
        "id": "ydOo9t7G0dFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5ExwSp3hyu_d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                         train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                         test_size=0.1, # use 1- % of training data for validation split,\n",
        "                                         random_state=42)"
      ],
      "metadata": {
        "id": "RBHalTl-0bnv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWoMCQ4u2EWF",
        "outputId": "4def05f3-283b-46c4-94b1-c3b715813b6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLIqXMqR2zPZ",
        "outputId": "5525d788-b52e-4d28-fc47-37d09ffb1400"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text in numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things\n",
        "you'll have to do before you can build a model is to convert\n",
        "your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenization -direct mapping of token (a token could be a word or a\n",
        "character) to number\n",
        "* Embedding - create a matrix of feature vector for each token \n",
        "(the size of the feature learned)"
      ],
      "metadata": {
        "id": "uudPYgGBDv-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text vectorization (tokenization)"
      ],
      "metadata": {
        "id": "1jgZkNawEeND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=10000,# how many words in the vocabulary (automatically add <OOV>),\n",
        "                   standardize=\"lower_and_strip_punctuation\",\n",
        "                   split=\"whitespace\",\n",
        "                   ngrams=None, # create groups of words\n",
        "                   output_mode = \"int\", # create groups of n-words?\n",
        "                   output_sequence_length = None, # how long do you want your sequences to be\n",
        "                   pad_to_max_tokens=True)"
      ],
      "metadata": {
        "id": "HWyUj6CVEcjg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences[0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XQcR2iMIlFs",
        "outputId": "b5f31d3c-0da7-4a9d-bec7-29b591a5b6eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lWSfLOiEyQk",
        "outputId": "5736117c-662e-4e2c-b769-d1cf8f4a06ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vacabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                 output_mode=\"int\",\n",
        "                 output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "BntrQ3B2Itan"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "xBF3Vc1xtSt_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-ZLJIqLtsks",
        "outputId": "a215cb88-d56c-4f05-f47f-f3d245b800bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "    \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAAyrU6ouUv8",
        "outputId": "cb916d63-fa6e-4914-ea26-fce74a514060"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " I agree with certain cultural appropriation things but honestly if u looked at my house it screams appropriation bc Buddhas and stuff-    \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   8, 1331,   14, 2530,    1, 6209,  429,   30, 1518,   47,  142,\n",
              "        2404,   17,   13,  318]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the uniqu words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {len(top_5_words)}\")\n",
        "print(f\"5 least common words: {len(bottom_5_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QIzX6Qzvd6w",
        "outputId": "2713d9d2-ceec-4cb7-c954-1c4d14fc8015"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: 5\n",
            "5 least common words: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's \n",
        "embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example,\n",
        " a value of 100 would mean each token gets represented 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding\n",
        "layer"
      ],
      "metadata": {
        "id": "1S7DrnOzxutH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim= max_vocab_length,\n",
        "                output_dim=128,\n",
        "                embeddings_initializer=\"uniform\",\n",
        "                input_length=max_length # how long is each input\n",
        "                )\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig_N24C7wnE2",
        "outputId": "4fe00266-89cd-4321-a449-cd26a6ea7b20"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f746e7e6910>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "    \\n\\n Embedded version:\")\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Poj6cnqzkao",
        "outputId": "001ecf59-237f-4e13-f110-e1373fc6c932"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " @TelegraphWorld lets hope it's a upper class white mass murderer....''' Mmmm    \n",
            "\n",
            " Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04594226, -0.03645831,  0.00712911, ...,  0.03878795,\n",
              "          0.01866242, -0.02540636],\n",
              "        [ 0.04127504,  0.03462315,  0.00386765, ..., -0.03034254,\n",
              "         -0.04252139,  0.01042348],\n",
              "        [-0.04081737,  0.03169334,  0.02622361, ..., -0.04626269,\n",
              "          0.0134769 , -0.00339732],\n",
              "        ...,\n",
              "        [ 0.01276363,  0.0051802 , -0.01602538, ...,  0.04153191,\n",
              "          0.04407841, -0.01260151],\n",
              "        [ 0.01276363,  0.0051802 , -0.01602538, ...,  0.04153191,\n",
              "          0.04407841, -0.01260151],\n",
              "        [ 0.01276363,  0.0051802 , -0.01602538, ...,  0.04153191,\n",
              "          0.04407841, -0.01260151]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Bz7Zdm0T-y",
        "outputId": "4759830c-a077-4fb3-a8b3-ee6bd9c258a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.04594226, -0.03645831,  0.00712911,  0.03604725, -0.00957351,\n",
              "        -0.01333549,  0.0251222 , -0.04205329,  0.03000725, -0.00511502,\n",
              "        -0.03477848,  0.03320439,  0.04993335,  0.0499458 , -0.03767116,\n",
              "        -0.01120217,  0.00660501, -0.02673926,  0.02736117,  0.03254887,\n",
              "         0.04340154,  0.01176526,  0.04938463, -0.0039129 , -0.02031884,\n",
              "         0.04534436, -0.00034185, -0.02371023, -0.01944155, -0.01247442,\n",
              "         0.03935912,  0.02998959,  0.04397566, -0.02277901, -0.02434142,\n",
              "        -0.01506662, -0.04637642,  0.03825745,  0.02587328,  0.02068407,\n",
              "        -0.0470474 , -0.02589692, -0.00026321,  0.04838226, -0.03506712,\n",
              "         0.04107591,  0.03032816,  0.03644115, -0.00020991,  0.04795175,\n",
              "        -0.02860086, -0.0270991 ,  0.01432564, -0.03515195, -0.00203944,\n",
              "         0.04254932,  0.02740603, -0.03046254, -0.03087023, -0.01321245,\n",
              "        -0.03392911,  0.01133953,  0.02022294, -0.02035348, -0.02474139,\n",
              "        -0.02788898, -0.02811259, -0.04447877, -0.04366243, -0.04126571,\n",
              "        -0.02940376,  0.04940702,  0.00740989,  0.02747817, -0.04639125,\n",
              "         0.03740256,  0.03192842,  0.01659219,  0.02481965,  0.02208186,\n",
              "         0.03444684, -0.00120901,  0.0404087 , -0.00764478,  0.0362504 ,\n",
              "        -0.03346993, -0.03572885,  0.03302637, -0.03059316,  0.03044304,\n",
              "         0.04223814, -0.04227846, -0.03960781, -0.02244495,  0.00788032,\n",
              "        -0.04004294,  0.01656554, -0.04718895, -0.02311962,  0.0177783 ,\n",
              "        -0.04303287,  0.00949515, -0.0499848 , -0.04940153, -0.02145599,\n",
              "         0.0109736 ,  0.02024798, -0.03687396, -0.02988927,  0.04763747,\n",
              "        -0.04760306,  0.01946961, -0.03411915, -0.00855876,  0.04573936,\n",
              "        -0.02178574, -0.02218061, -0.02561378, -0.00889831,  0.01494009,\n",
              "         0.02166648,  0.03390092, -0.04617811,  0.03283728,  0.03863804,\n",
              "         0.03878795,  0.01866242, -0.02540636], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " '@')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers,\n",
        "it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline), this is from Sklearn ML map:\n",
        "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidrectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer\n",
        "learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we going to apporach all of these?\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a model\n",
        "* Build amodel\n",
        "* Fit a model\n",
        "* Evaluate a model"
      ],
      "metadata": {
        "id": "dA7O4mBI4oFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a baseline\n",
        "As with all machine learning modelling experiments, it;s important to create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Mulinomial Naive Bayes using\n",
        "the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> Note: It's common practice to us non-DL algorithms as a baseline\n",
        "because of their speed and then later using DL to see if you can\n",
        "imporve upon them"
      ],
      "metadata": {
        "id": "Lj8UZyDL8e0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDEvpbIX1JpJ",
        "outputId": "e8dde2b6-494a-4032-80c4-0806dfa27472"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences,val_labels)\n",
        "print(f\"Our baseline model achievs an accuracy of: {baseline_score * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKZeIyi_9ZnX",
        "outputId": "e1821d0f-3258-408c-e176-8a12e01cc54d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achievs an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Ycz8kl_Ia_",
        "outputId": "b3ccb78b-bbb4-4d8a-e25b-5f2c3a8d8b07"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHPHdU_KAR85",
        "outputId": "3e76c66a-01b9-4ffd-f424-595ab49b0734"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiVoKTryAgEx",
        "outputId": "35bd92b6-6dd1-4d6e-adcd-2292a9e4a2d1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics,\n",
        "however, this will be cumbersome and could easily be fixed with a function.\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using\n",
        "using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ],
      "metadata": {
        "id": "GFooTMyxBfj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classfication model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _= precision_recall_fscore_support(y_true,y_pred,average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "            \"precision\": model_precision,\n",
        "            \"recall\": model_recall,\n",
        "            \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "xeShA-17AiGV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emAFXQBGMSTj",
        "outputId": "a98e2675-9c17-45f1-a27d-65877d7d55b3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "F44CBF1gNZKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback （need to create a new one for each model）\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "1SNMFTuQMkf6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "# x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want  binary outputs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name = \"model_1_dense\")"
      ],
      "metadata": {
        "id": "ueogvP0gXDBI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CxFk5GrXTSp",
        "outputId": "6220134d-2d57-4d6a-d621-0e5283979587"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "SnmQHUlqXafK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history= model_1.fit(x=train_sentences,\n",
        "               y=train_labels,\n",
        "               epochs=5,\n",
        "               validation_data=(val_sentences,val_labels),\n",
        "               callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfYKwmfQYjzi",
        "outputId": "3a2f3e81-22eb-4c72-d0be-50cab422ef6b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230216-012422\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 27ms/step - loss: 0.6325 - accuracy: 0.6555 - val_loss: 0.5691 - val_accuracy: 0.7559\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.4666 - accuracy: 0.8294 - val_loss: 0.4747 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3397 - accuracy: 0.8784 - val_loss: 0.4539 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.2554 - accuracy: 0.9080 - val_loss: 0.4567 - val_accuracy: 0.7808\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1954 - accuracy: 0.9340 - val_loss: 0.4734 - val_accuracy: 0.7822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODxDZ-KSaGTh",
        "outputId": "05059846-ce19-4ee5-82e1-45ecd40340e1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4734395444393158, 0.7821522355079651]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXg4gUMyZLJR",
        "outputId": "9dc9bb79-f5eb-4e66-f744-78efd01c0672"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVWRc042cKDI",
        "outputId": "39166e76-3f8a-4ab2-8910-b08297800ef7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                   y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqU8Bs16eWlx",
        "outputId": "6f938ffb-b15c-4b5b-adfe-55eab6bb11bc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'precision': 0.7877268665884849,\n",
              " 'recall': 0.7821522309711286,\n",
              " 'f1': 0.7787825179570674}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUaZadOjeliG",
        "outputId": "3b80148e-6ac3-469b-e528-9edda1f43c18"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzOp9s5nem-0",
        "outputId": "36129dd8-ba5d-4b2b-d674-63f29f780519"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing learned embeddings"
      ],
      "metadata": {
        "id": "AmF69jaK0F_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "id": "skFcvgeeexkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b773fb-fa37-4d81-e85f-73eece34e928"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au6VUy9S0jN_",
        "outputId": "789bfbae-3adb-47ae-ffdb-cba3d5741830"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for ~5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HxZ9ljN14sK",
        "outputId": "e99df0cc-6d9a-4540-d91e-c8d75840b7c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1085796 , -0.02575858, -0.07700494, ..., -0.04790403,\n",
              "        -0.0674326 , -0.03111559],\n",
              "       [-0.10121714, -0.0275671 , -0.06368901, ..., -0.04602059,\n",
              "        -0.06767766, -0.02010179],\n",
              "       [-0.06509251, -0.01679299, -0.04609485, ..., -0.06703962,\n",
              "        -0.05738913, -0.03291306],\n",
              "       ...,\n",
              "       [ 0.02758039,  0.03019187,  0.01152258, ..., -0.03050214,\n",
              "        -0.04018402, -0.01727664],\n",
              "       [-0.01642279,  0.04919182, -0.04315494, ..., -0.00287989,\n",
              "        -0.01065424,  0.02801652],\n",
              "       [-0.02481541,  0.08538371, -0.0287295 , ..., -0.02054878,\n",
              "        -0.01961271, -0.04865291]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got the embedding matrix our model has learned to represent\n",
        "our tokens, let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/\n",
        "\n",
        "And Tensorflow also has an incredible guide on word embeddings themselves:\n",
        "https://www.tensorflow.org/text/guide/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk"
      ],
      "metadata": {
        "id": "wF-6MMlS3_YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embedding files (we git this from TensorFlow's word embedings documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "IrOhZaZJ5kEz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files from Colab to upload to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "QKovLpyk6iOC",
        "outputId": "7aa2633c-1695-472e-ac44-afe2603d09d4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c4e772b-0991-4fee-89d7-4f2001a6c3b7\", \"vectors.tsv\", 16006933)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5089a8a-a646-47a1-a295-67faba6d3dec\", \"metadata.tsv\", 80388)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recureent Neural Networks"
      ],
      "metadata": {
        "id": "jj5L0WThBCXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text)-> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ],
      "metadata": {
        "id": "A0zcqYRXCIri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creat an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(64, return_sequences = True)(x)\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "x = layers.Dense(64, activation= \"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "Xmw51jhW8XwJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22K_d66SBA0R",
        "outputId": "8b30c7dc-06d2-4378-c75f-dda483c5e49a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "91JltLKwIpWM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                train_labels,\n",
        "                epochs=5,\n",
        "                validation_data=(val_sentences, val_labels),\n",
        "                callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_2_LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQfyL2mZI4A8",
        "outputId": "f1daa683-ac88-4382-93a2-823a7deae126"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230216-012918\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 24ms/step - loss: 0.3807 - accuracy: 0.8361 - val_loss: 0.4563 - val_accuracy: 0.7874\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.2432 - accuracy: 0.9072 - val_loss: 0.5288 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.1718 - accuracy: 0.9369 - val_loss: 0.6147 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.1279 - accuracy: 0.9546 - val_loss: 0.6197 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0939 - accuracy: 0.9631 - val_loss: 0.9841 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2__pred_probs = model_2.predict(val_sentences)\n",
        "model_2__pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rH-03gCLITl",
        "outputId": "60736b32-ee06-4c51-c1d8-ea8aa171d3ae"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00230703],\n",
              "       [0.8242072 ],\n",
              "       [0.999795  ],\n",
              "       [0.0313331 ],\n",
              "       [0.00205021],\n",
              "       [0.9999706 ],\n",
              "       [0.8277461 ],\n",
              "       [0.99999225],\n",
              "       [0.9999857 ],\n",
              "       [0.48686412]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert modl 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2__pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vk_ZoYnJLYd",
        "outputId": "42e6d722-2e31-4a00-de18-f1b18d969e35"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                   y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TupUH53VLCWc",
        "outputId": "0d957373-9199-48e6-df80-f01f736b4040"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'precision': 0.7791293682827463,\n",
              " 'recall': 0.7716535433070866,\n",
              " 'f1': 0.7672567495577469}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqp941XFMBgs",
        "outputId": "b1f7dad1-7406-40ce-c774-2bd77d9049c4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent\n",
        "unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less\n",
        "parameters."
      ],
      "metadata": {
        "id": "jCMii9RTxGre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs =layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name = \"model_3_GRU\")"
      ],
      "metadata": {
        "id": "1MxJitVkMcdW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaAHoNDM0gPg",
        "outputId": "ee584564-8bc5-480c-a528-c9c5a7024069"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer = tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "v9iCAsnT0deF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                train_labels,\n",
        "                epochs=5,\n",
        "                validation_data=(val_sentences,val_labels),\n",
        "                callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                    \"model_3_GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUk9tO5S0_0z",
        "outputId": "788a16ac-914d-4555-c998-6e771e1e7754"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20230216-012944\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 23ms/step - loss: 0.1937 - accuracy: 0.9215 - val_loss: 0.6875 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0974 - accuracy: 0.9669 - val_loss: 0.7174 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.8991 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0665 - accuracy: 0.9749 - val_loss: 0.9937 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0540 - accuracy: 0.9765 - val_loss: 1.2446 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4peDbet17ha",
        "outputId": "32930eea-ae47-4a5a-f74c-9083328ae1b6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.8781138e-04],\n",
              "       [6.1039847e-01],\n",
              "       [9.9976438e-01],\n",
              "       [6.2781565e-02],\n",
              "       [1.3649241e-04],\n",
              "       [9.9989235e-01],\n",
              "       [9.9188608e-01],\n",
              "       [9.9990022e-01],\n",
              "       [9.9990582e-01],\n",
              "       [8.9162093e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc1HugyR2hoL",
        "outputId": "783c4e92-2610-444a-aa7b-98f9bc4cf835"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                   y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVG_GZgw2vwk",
        "outputId": "a42f1bd3-3ef6-4780-9dc7-bfc68082abb6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'precision': 0.773049502603257,\n",
              " 'recall': 0.7716535433070866,\n",
              " 'f1': 0.7697096359746837}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidrectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd sread an English \n",
        "sentence) however, a bidirectional RNN goes from right to left as well\n",
        "as left to right."
      ],
      "metadata": {
        "id": "3-gIQouL3q2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "metadata": {
        "id": "N_tiAZJ83CEc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIC_NwGP5niq",
        "outputId": "f5bb5bdd-b23f-4924-fda7-c4d616d67649"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "iJFSOHFN6HKy"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                train_labels,\n",
        "                epochs=5,\n",
        "                validation_data=(val_sentences, val_labels),\n",
        "                callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_4_bidirectional\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVemdk0_6s_H",
        "outputId": "8e280711-ad94-4a7f-dfba-10eec1f16b85"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230216-013029\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 18s 51ms/step - loss: 0.1217 - accuracy: 0.9568 - val_loss: 0.9271 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0634 - accuracy: 0.9739 - val_loss: 1.0279 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0525 - accuracy: 0.9761 - val_loss: 1.1487 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0429 - accuracy: 0.9787 - val_loss: 1.8068 - val_accuracy: 0.7598\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0457 - accuracy: 0.9790 - val_loss: 1.3605 - val_accuracy: 0.7612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAD08iMt7B8k",
        "outputId": "55f3dbad-3e3e-422a-eff4-c6086ca78516"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.3367362e-03],\n",
              "       [5.7459903e-01],\n",
              "       [9.9976665e-01],\n",
              "       [2.3529260e-01],\n",
              "       [2.5292291e-05],\n",
              "       [9.9995816e-01],\n",
              "       [9.4061053e-01],\n",
              "       [9.9997479e-01],\n",
              "       [9.9996173e-01],\n",
              "       [8.3121777e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probs o pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl99WNo27s2o",
        "outputId": "d15692db-e0e6-492a-956a-72bb926dca92"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                   y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCL-QKMs7RS8",
        "outputId": "3b2e7408-0dd1-425c-cf9b-dbf0c07702cd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.11548556430446,\n",
              " 'precision': 0.7612627209133627,\n",
              " 'recall': 0.7611548556430446,\n",
              " 'f1': 0.7598431815524319}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "395l2XFQ7h1S",
        "outputId": "f7569092-4834-4ee2-e819-b438cded01d7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D Convolutional Neural Network\n",
        "\n",
        "We've used CNNs for images but images ares typically 2D (height * width)\n",
        "...however, oyt text data is 1D.\n",
        "\n",
        "Previously we've Conv2D for our image data but now we're going to use\n",
        "Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s)\n",
        "(typically Conv1D + pooling) -> Outpus (class probabilities)"
      ],
      "metadata": {
        "id": "vBM4w-hM8NOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "For different explanations of parameters see:\n",
        "* https://poloclub.github.io/cnn-explainer/ (this is for 2D but can relate\n",
        "1D data)\n",
        "\n",
        "* Difference between \"same\" and \"valid\" padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"
      ],
      "metadata": {
        "id": "74OAAMFM-jyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "             kernel_size=5, # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "             strides=1, # default\n",
        "             activation=\"relu\",\n",
        "             padding=\"same\") # default = \"valid\", the output is smaller than the input shape, \"same\" means output is same shape as input\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest\" \n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H396mo1p8L3J",
        "outputId": "a6ceac6d-2b4c-4951-ae8f-f43da2f3f82a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsprjCfh-iw5",
        "outputId": "1eca3cca-684e-4e5e-afdf-e2a53b8ec87c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.09113242, -0.00958658, -0.04850151, ..., -0.06693354,\n",
              "         -0.08442527, -0.00571118],\n",
              "        [-0.06605668, -0.06414277, -0.00457383, ..., -0.03989825,\n",
              "         -0.05272823, -0.04686037],\n",
              "        [-0.04737524, -0.04738245,  0.00038254, ..., -0.02440342,\n",
              "         -0.03700876, -0.04553024],\n",
              "        ...,\n",
              "        [-0.08723652, -0.02082578, -0.04596107, ..., -0.03031716,\n",
              "         -0.03637241, -0.01991101],\n",
              "        [-0.08723652, -0.02082578, -0.04596107, ..., -0.03031716,\n",
              "         -0.03637241, -0.01991101],\n",
              "        [-0.08723652, -0.02082578, -0.04596107, ..., -0.03031716,\n",
              "         -0.03637241, -0.01991101]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_1d_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY9PSI_bDh-w",
        "outputId": "206ad20b-73e2-4ada-a38c-165a5ddebba5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 64), dtype=float32, numpy=\n",
              "array([[[3.88522558e-02, 0.00000000e+00, 1.99179165e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 1.33598633e-02, 1.10550709e-02,\n",
              "         1.46168377e-02, 0.00000000e+00, 0.00000000e+00, 2.03368627e-02,\n",
              "         0.00000000e+00, 1.15314126e-02, 4.73724641e-02, 2.01886520e-02,\n",
              "         1.84193999e-02, 0.00000000e+00, 4.24611755e-02, 0.00000000e+00,\n",
              "         3.68745923e-02, 0.00000000e+00, 4.55405563e-03, 0.00000000e+00,\n",
              "         7.10368156e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         4.30875346e-02, 2.74965838e-02, 1.01946294e-02, 3.72011699e-02,\n",
              "         1.59083493e-02, 2.43560709e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         5.29264361e-02, 0.00000000e+00, 4.89838347e-02, 0.00000000e+00,\n",
              "         2.02714633e-02, 4.41401638e-02, 0.00000000e+00, 4.88928482e-02,\n",
              "         1.55948605e-02, 2.36879364e-02, 2.74646524e-02, 2.07678750e-02,\n",
              "         1.16437171e-02, 4.31033596e-02, 4.36570719e-02, 0.00000000e+00,\n",
              "         1.13418393e-01, 8.63957256e-02, 0.00000000e+00, 3.09320632e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 2.36719698e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.49304891e-05, 1.52108632e-02, 1.65856984e-02],\n",
              "        [0.00000000e+00, 0.00000000e+00, 3.41213495e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 4.08758856e-02, 0.00000000e+00, 3.33754830e-02,\n",
              "         7.81036392e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 2.15198379e-02, 7.92457238e-02,\n",
              "         2.13269461e-02, 2.30687987e-02, 3.44896689e-02, 8.44614506e-02,\n",
              "         0.00000000e+00, 4.40864637e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.15577188e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         4.15968969e-02, 7.77096003e-02, 0.00000000e+00, 8.85520317e-03,\n",
              "         0.00000000e+00, 6.00531511e-03, 1.11187752e-02, 0.00000000e+00,\n",
              "         7.54115954e-02, 0.00000000e+00, 1.90154985e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.04907747e-03, 0.00000000e+00, 6.41160458e-02,\n",
              "         0.00000000e+00, 1.36733409e-02, 2.11138674e-03, 0.00000000e+00,\n",
              "         1.32580232e-02, 7.73350075e-02, 5.23815230e-02, 0.00000000e+00,\n",
              "         8.54931250e-02, 5.79310320e-02, 0.00000000e+00, 1.46757634e-02,\n",
              "         6.20595850e-02, 3.21927667e-02, 0.00000000e+00, 1.83150396e-02,\n",
              "         2.51034163e-02, 2.50511728e-02, 0.00000000e+00, 6.02532588e-02],\n",
              "        [4.48269248e-02, 0.00000000e+00, 4.64320183e-03, 6.58413917e-02,\n",
              "         1.35670900e-02, 6.78587258e-02, 1.38653554e-02, 7.45941885e-04,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.60391194e-02,\n",
              "         0.00000000e+00, 8.13720524e-02, 3.32820266e-02, 0.00000000e+00,\n",
              "         7.23240674e-02, 2.34381631e-02, 3.15998234e-02, 3.72527912e-02,\n",
              "         3.61032560e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         4.54116315e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.52775364e-02, 1.05425574e-01, 5.04853725e-02, 6.87257349e-02,\n",
              "         0.00000000e+00, 6.55355453e-02, 4.31058519e-02, 0.00000000e+00,\n",
              "         1.86237860e-02, 5.73342703e-02, 5.91091961e-02, 0.00000000e+00,\n",
              "         6.45938609e-03, 4.74348292e-03, 0.00000000e+00, 5.96739054e-02,\n",
              "         1.28830299e-01, 0.00000000e+00, 0.00000000e+00, 9.72831324e-02,\n",
              "         6.06181696e-02, 5.23846596e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         5.35911955e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         4.05672006e-02, 4.40000780e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         3.06786988e-02, 0.00000000e+00, 0.00000000e+00, 8.40869453e-03],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.97478980e-02, 6.41994029e-02,\n",
              "         0.00000000e+00, 5.52259386e-02, 0.00000000e+00, 3.89540493e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 5.22701144e-02, 2.72739865e-03,\n",
              "         8.01288411e-02, 0.00000000e+00, 1.76574513e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 2.18818337e-02, 5.82571886e-03, 0.00000000e+00,\n",
              "         7.70039111e-02, 3.49419639e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.46070419e-02, 4.53345776e-02, 6.96100900e-03, 1.60980690e-02,\n",
              "         2.18840186e-02, 5.00264578e-02, 2.11441237e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 2.75019296e-02, 3.55399400e-02, 0.00000000e+00,\n",
              "         5.82017601e-02, 5.26453629e-02, 0.00000000e+00, 1.08094200e-01,\n",
              "         3.53610441e-02, 6.34673983e-04, 0.00000000e+00, 9.22781527e-02,\n",
              "         1.16100147e-01, 2.30710879e-02, 5.43740392e-02, 0.00000000e+00,\n",
              "         6.79970458e-02, 3.64110805e-02, 0.00000000e+00, 4.44126576e-02,\n",
              "         4.72445264e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.49940699e-02, 2.70127561e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [6.88904338e-03, 0.00000000e+00, 6.11326173e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 3.51692364e-02, 1.02710433e-01,\n",
              "         0.00000000e+00, 2.63337083e-02, 0.00000000e+00, 5.97431995e-02,\n",
              "         0.00000000e+00, 4.50836308e-02, 7.06723928e-02, 0.00000000e+00,\n",
              "         4.55708653e-02, 0.00000000e+00, 6.19543344e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 8.34759697e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.03353307e-01, 3.13590914e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 5.50328381e-03, 0.00000000e+00, 6.00973666e-02,\n",
              "         0.00000000e+00, 2.05577798e-02, 2.79647484e-02, 4.71973792e-02,\n",
              "         2.23703701e-02, 1.06774613e-01, 1.72790036e-01, 0.00000000e+00,\n",
              "         5.50224371e-02, 2.40170285e-02, 0.00000000e+00, 1.58028781e-01,\n",
              "         0.00000000e+00, 4.84340303e-02, 0.00000000e+00, 2.83480845e-02,\n",
              "         6.73982874e-03, 7.76761621e-02, 3.20995152e-02, 0.00000000e+00,\n",
              "         1.13778688e-01, 5.89644574e-02, 1.32468324e-02, 7.11154193e-02,\n",
              "         3.81636471e-02, 2.22795941e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 1.73567794e-03, 0.00000000e+00, 0.00000000e+00],\n",
              "        [1.62278228e-02, 0.00000000e+00, 6.44947365e-02, 2.44513545e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 4.54581454e-02, 6.71155564e-03,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 4.83565778e-02, 6.05453327e-02, 1.94074791e-02,\n",
              "         1.08600706e-02, 0.00000000e+00, 3.06196772e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 1.41693428e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         6.30599260e-02, 1.89925041e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         3.93039957e-02, 0.00000000e+00, 0.00000000e+00, 3.96974981e-02,\n",
              "         2.67713107e-02, 4.68903780e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         3.39652710e-02, 4.91736457e-02, 1.17738575e-01, 0.00000000e+00,\n",
              "         3.13492641e-02, 3.57252099e-02, 0.00000000e+00, 1.17201179e-01,\n",
              "         0.00000000e+00, 0.00000000e+00, 1.30965775e-02, 5.54741323e-02,\n",
              "         8.06677639e-02, 1.03369802e-01, 1.37880996e-01, 0.00000000e+00,\n",
              "         6.13103136e-02, 0.00000000e+00, 0.00000000e+00, 6.22312129e-02,\n",
              "         3.84549499e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 1.87737215e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [3.03897206e-02, 0.00000000e+00, 6.37473464e-02, 1.33701283e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 4.12266143e-02, 5.55773601e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.88740441e-03,\n",
              "         0.00000000e+00, 7.43901879e-02, 4.83516455e-02, 3.07318196e-02,\n",
              "         8.40650871e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 4.92330268e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.20930749e-02, 2.62442995e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.48816356e-02, 5.33333570e-02, 4.71707135e-02, 4.93610278e-02,\n",
              "         1.44101400e-02, 4.12204750e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.07599627e-02, 5.67200184e-02, 1.36519715e-01, 0.00000000e+00,\n",
              "         1.01978881e-02, 1.41690932e-02, 0.00000000e+00, 9.07458216e-02,\n",
              "         3.06654871e-02, 1.25479773e-02, 0.00000000e+00, 2.90790182e-02,\n",
              "         6.13738969e-02, 5.74283414e-02, 5.03979623e-02, 5.11359498e-02,\n",
              "         1.10526823e-01, 3.12354751e-02, 0.00000000e+00, 6.74249008e-02,\n",
              "         7.12618157e-02, 2.31808238e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 2.55899895e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.77963784e-02, 0.00000000e+00, 8.18542689e-02, 2.74875965e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.60463294e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.27051273e-02, 3.49158347e-02, 2.68303715e-02,\n",
              "         2.33916976e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.15564014e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.61494243e-02, 1.95299461e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.32653514e-02, 5.86882532e-02, 1.19281821e-02, 3.15555185e-02,\n",
              "         4.41806242e-02, 5.22734262e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.69381630e-03, 4.53425348e-02, 1.20770410e-01, 0.00000000e+00,\n",
              "         4.71967533e-02, 8.30730423e-03, 0.00000000e+00, 7.08441287e-02,\n",
              "         3.81221175e-02, 2.01680772e-02, 3.53901368e-03, 6.34982958e-02,\n",
              "         5.35210073e-02, 5.54678999e-02, 4.58896309e-02, 3.78043763e-02,\n",
              "         8.55586082e-02, 2.08454356e-02, 0.00000000e+00, 8.57917666e-02,\n",
              "         4.07125279e-02, 1.28794461e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.19866075e-03, 2.13724021e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.77963784e-02, 0.00000000e+00, 8.18542689e-02, 2.74875965e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.60463294e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.27051273e-02, 3.49158347e-02, 2.68303715e-02,\n",
              "         2.33916976e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.15564014e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.61494243e-02, 1.95299461e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.32653514e-02, 5.86882532e-02, 1.19281821e-02, 3.15555185e-02,\n",
              "         4.41806242e-02, 5.22734262e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.69381630e-03, 4.53425348e-02, 1.20770410e-01, 0.00000000e+00,\n",
              "         4.71967533e-02, 8.30730423e-03, 0.00000000e+00, 7.08441287e-02,\n",
              "         3.81221175e-02, 2.01680772e-02, 3.53901368e-03, 6.34982958e-02,\n",
              "         5.35210073e-02, 5.54678999e-02, 4.58896309e-02, 3.78043763e-02,\n",
              "         8.55586082e-02, 2.08454356e-02, 0.00000000e+00, 8.57917666e-02,\n",
              "         4.07125279e-02, 1.28794461e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.19866075e-03, 2.13724021e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.77963784e-02, 0.00000000e+00, 8.18542689e-02, 2.74875965e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.60463294e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.27051273e-02, 3.49158347e-02, 2.68303715e-02,\n",
              "         2.33916976e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.15564014e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.61494243e-02, 1.95299461e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.32653514e-02, 5.86882532e-02, 1.19281821e-02, 3.15555185e-02,\n",
              "         4.41806242e-02, 5.22734262e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.69381630e-03, 4.53425348e-02, 1.20770410e-01, 0.00000000e+00,\n",
              "         4.71967533e-02, 8.30730423e-03, 0.00000000e+00, 7.08441287e-02,\n",
              "         3.81221175e-02, 2.01680772e-02, 3.53901368e-03, 6.34982958e-02,\n",
              "         5.35210073e-02, 5.54678999e-02, 4.58896309e-02, 3.78043763e-02,\n",
              "         8.55586082e-02, 2.08454356e-02, 0.00000000e+00, 8.57917666e-02,\n",
              "         4.07125279e-02, 1.28794461e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.19866075e-03, 2.13724021e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.77963784e-02, 0.00000000e+00, 8.18542689e-02, 2.74875965e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.60463294e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.27051273e-02, 3.49158347e-02, 2.68303715e-02,\n",
              "         2.33916976e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.15564014e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.61494243e-02, 1.95299461e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.32653514e-02, 5.86882532e-02, 1.19281821e-02, 3.15555185e-02,\n",
              "         4.41806242e-02, 5.22734262e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.69381630e-03, 4.53425348e-02, 1.20770410e-01, 0.00000000e+00,\n",
              "         4.71967533e-02, 8.30730423e-03, 0.00000000e+00, 7.08441287e-02,\n",
              "         3.81221175e-02, 2.01680772e-02, 3.53901368e-03, 6.34982958e-02,\n",
              "         5.35210073e-02, 5.54678999e-02, 4.58896309e-02, 3.78043763e-02,\n",
              "         8.55586082e-02, 2.08454356e-02, 0.00000000e+00, 8.57917666e-02,\n",
              "         4.07125279e-02, 1.28794461e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.19866075e-03, 2.13724021e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.77963784e-02, 0.00000000e+00, 8.18542689e-02, 2.74875965e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.60463294e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.27051273e-02, 3.49158347e-02, 2.68303715e-02,\n",
              "         2.33916976e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.15564014e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.61494243e-02, 1.95299461e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.32653514e-02, 5.86882532e-02, 1.19281821e-02, 3.15555185e-02,\n",
              "         4.41806242e-02, 5.22734262e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.69381630e-03, 4.53425348e-02, 1.20770410e-01, 0.00000000e+00,\n",
              "         4.71967533e-02, 8.30730423e-03, 0.00000000e+00, 7.08441287e-02,\n",
              "         3.81221175e-02, 2.01680772e-02, 3.53901368e-03, 6.34982958e-02,\n",
              "         5.35210073e-02, 5.54678999e-02, 4.58896309e-02, 3.78043763e-02,\n",
              "         8.55586082e-02, 2.08454356e-02, 0.00000000e+00, 8.57917666e-02,\n",
              "         4.07125279e-02, 1.28794461e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.19866075e-03, 2.13724021e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.77963765e-02, 0.00000000e+00, 8.18542838e-02, 2.74875984e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.60463220e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 7.27051497e-02, 3.49158198e-02, 2.68303659e-02,\n",
              "         2.33917050e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 3.15564312e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         8.61494243e-02, 1.95300579e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.32653439e-02, 5.86882643e-02, 1.19281821e-02, 3.15555260e-02,\n",
              "         4.41806093e-02, 5.22734299e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.69380885e-03, 4.53425273e-02, 1.20770410e-01, 0.00000000e+00,\n",
              "         4.71967533e-02, 8.30730610e-03, 0.00000000e+00, 7.08441287e-02,\n",
              "         3.81221101e-02, 2.01680753e-02, 3.53900343e-03, 6.34982958e-02,\n",
              "         5.35210297e-02, 5.54678924e-02, 4.58896235e-02, 3.78043763e-02,\n",
              "         8.55586082e-02, 2.08454318e-02, 0.00000000e+00, 8.57917815e-02,\n",
              "         4.07125242e-02, 1.28779560e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "         2.19866075e-03, 2.13724226e-02, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.69902032e-02, 0.00000000e+00, 9.45500508e-02, 1.84670649e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 6.50701672e-03, 7.15902522e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 5.21734357e-03, 6.81053102e-03,\n",
              "         0.00000000e+00, 5.29110841e-02, 1.42493080e-02, 2.77491901e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 6.54569790e-02, 0.00000000e+00, 1.14649143e-02,\n",
              "         4.53372039e-02, 3.14008072e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         7.47137442e-02, 7.34518468e-02, 2.15805843e-02, 2.43249312e-02,\n",
              "         2.98784543e-02, 5.20001128e-02, 0.00000000e+00, 1.34276580e-02,\n",
              "         0.00000000e+00, 2.65558660e-02, 7.24730492e-02, 0.00000000e+00,\n",
              "         3.38706113e-02, 1.20543223e-02, 0.00000000e+00, 2.45240889e-02,\n",
              "         5.15165552e-02, 0.00000000e+00, 0.00000000e+00, 7.61494599e-03,\n",
              "         3.45893539e-02, 6.31865337e-02, 1.96216684e-02, 4.49819602e-02,\n",
              "         5.46965152e-02, 0.00000000e+00, 0.00000000e+00, 8.94872174e-02,\n",
              "         8.15159641e-04, 3.39645669e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "        [2.61871871e-02, 0.00000000e+00, 5.41358329e-02, 1.05380379e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 6.70489855e-03, 8.30501691e-02,\n",
              "         8.71890038e-03, 0.00000000e+00, 3.26599972e-03, 1.48176067e-02,\n",
              "         0.00000000e+00, 7.38973171e-03, 0.00000000e+00, 1.11842481e-03,\n",
              "         1.30099738e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 4.75314930e-02, 0.00000000e+00, 1.63126513e-02,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.78970336e-03,\n",
              "         5.66076599e-02, 8.23045820e-02, 5.01021147e-02, 7.15422584e-03,\n",
              "         3.97197455e-02, 7.71982819e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         0.00000000e+00, 0.00000000e+00, 4.82212640e-02, 0.00000000e+00,\n",
              "         1.47340260e-02, 0.00000000e+00, 0.00000000e+00, 2.49753296e-02,\n",
              "         1.03193514e-01, 0.00000000e+00, 0.00000000e+00, 2.18377728e-02,\n",
              "         2.87257731e-02, 3.97475809e-02, 0.00000000e+00, 3.54918018e-02,\n",
              "         2.58693900e-02, 0.00000000e+00, 0.00000000e+00, 7.43702054e-02,\n",
              "         5.13829887e-02, 2.74350345e-02, 1.10632256e-02, 0.00000000e+00,\n",
              "         8.98526795e-03, 4.98964489e-02, 0.00000000e+00, 0.00000000e+00]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5,strides=1, activation=\"relu\", padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer = tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"])\n",
        "model_5.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-g1gqdVDmUU",
        "outputId": "affb38b3-e079-40fd-e9e7-936f3a5d9eb0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit th model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                train_labels,\n",
        "                epochs=5,\n",
        "                validation_data=(val_sentences, val_labels),\n",
        "                callbacks=[create_tensorboard_callback(SAVE_DIR,\"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbJAiVKYEyIx",
        "outputId": "4df3acac-96a5-4e7e-86a4-1c1c6cb06f2b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20230216-013124\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 13ms/step - loss: 0.1468 - accuracy: 0.9578 - val_loss: 0.8832 - val_accuracy: 0.7546\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 1.0059 - val_accuracy: 0.7546\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0609 - accuracy: 0.9762 - val_loss: 1.0419 - val_accuracy: 0.7585\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0556 - accuracy: 0.9774 - val_loss: 1.0735 - val_accuracy: 0.7467\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0553 - accuracy: 0.9793 - val_loss: 1.1277 - val_accuracy: 0.7520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our Conv1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qehPvgGuwR",
        "outputId": "ee4daa0c-45c0-47f9-d360-868db4990de6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.5372425e-03],\n",
              "       [9.4498879e-01],\n",
              "       [9.9994200e-01],\n",
              "       [8.6416982e-02],\n",
              "       [6.4954097e-06],\n",
              "       [9.9731004e-01],\n",
              "       [7.4456590e-01],\n",
              "       [9.9990296e-01],\n",
              "       [9.9999732e-01],\n",
              "       [2.8548005e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEA3-WwgHBpy",
        "outputId": "677d0e4c-02a5-40ae-e3e5-a954d196a089"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true= val_labels,\n",
        "                   y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HRCHTvCHOOG",
        "outputId": "1c3bb8af-d084-4c10-b1ca-7a86e9f92efb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.19685039370079,\n",
              " 'precision': 0.753207335992147,\n",
              " 'recall': 0.7519685039370079,\n",
              " 'f1': 0.7496488116181164}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYXSczFqHboZ",
        "outputId": "1c3ee7c3-d98c-4a2a-ce83-da15cdc33317"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we've built a few of our own models, let's try and use transfer\n",
        "learning for NLP, specifically using TensorFlow Hub's Universal\n",
        "Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/4"
      ],
      "metadata": {
        "id": "VjF_480-IrJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "            \"When you can the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACm4kCpOHgh1",
        "outputId": "9c9b489b-0de4-45cc-8d44-09578cd9e8e7"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
            "  0.02680988  0.05589838 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
            "  0.00030816  0.09105889  0.05874645 -0.03180629  0.01512474 -0.05162925\n",
            "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
            " -0.00337968 -0.04787356  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
            " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
            "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
            " -0.01360601  0.05998649 -0.10361788 -0.05195372  0.00232958 -0.02332531\n",
            " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNlmzOoNl2Wv",
        "outputId": "43d7719f-fb6f-431f-f80e-3370311ed492"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encode_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                       input_shape=[],\n",
        "                                       dtype=tf.string,\n",
        "                                       trainable=False,\n",
        "                                       name=\"USE\"\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mzs-HH4l57G",
        "outputId": "ade2d763-a643-4c8d-ed39-e6d99a6e4de8"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 =tf.keras.Sequential([\n",
        "    sentence_encode_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\",name=\"output_layer\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"])\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6L3mb1OnO1N",
        "outputId": "1146bde4-621e-4b56-cf08-535123af482d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                train_labels,\n",
        "                epochs=5,\n",
        "                validation_data=(val_sentences, val_labels),\n",
        "                callbacks=[create_tensorboard_callback(SAVE_DIR,\"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ZxkKZQn80L",
        "outputId": "dadbf865-6c5e-43a1-bf12-634bcca2e3d6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230216-013204\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 15ms/step - loss: 0.5020 - accuracy: 0.7843 - val_loss: 0.4503 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4140 - accuracy: 0.8159 - val_loss: 0.4391 - val_accuracy: 0.8045\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4006 - accuracy: 0.8206 - val_loss: 0.4323 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3925 - accuracy: 0.8246 - val_loss: 0.4295 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3855 - accuracy: 0.8305 - val_loss: 0.4288 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeewMmZkod3-",
        "outputId": "3c2c9233-92a5-4ca8-d925-dca458bfad8a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22316754],\n",
              "       [0.7642753 ],\n",
              "       [0.9902375 ],\n",
              "       [0.22730199],\n",
              "       [0.7905447 ],\n",
              "       [0.7758979 ],\n",
              "       [0.98187906],\n",
              "       [0.97926235],\n",
              "       [0.95916355],\n",
              "       [0.099905  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bc9qyrrpeW7",
        "outputId": "f502da4f-a038-4a56-ddb6-38bc557a5a00"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 perfomance metrics\n",
        "model_6_results = calculate_results(y_true = val_labels,\n",
        "                  y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dsdIatbps7d",
        "outputId": "13b212ee-e4c3-4024-fa8e-861782acaa73"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8135161424410383,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.8111730155404432}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CPzRzT4p7FN",
        "outputId": "29e03b9f-b3f5-4436-e36e-4af663799215"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate\n",
        "model_6 except we'll train it on 10% of the data."
      ],
      "metadata": {
        "id": "5Ioegd97e3cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## NOTE: Makinbg data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\",\"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_10_percent.head(), len(train_10_percent)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "id": "XuSh0wLtp_3R"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note** Be *very* careful when creating training/val/\n",
        "test splits that you don't leak data across the datasets, otherwise\n",
        "your model evaluation metrics will be wrong.  If something looks too good\n",
        "to be true ( a model trained on 10% of data outperforming the same mdoel trained\n",
        "on 100% of data)\n",
        "trust your gut and go back through to find where the error may lie."
      ],
      "metadata": {
        "id": "WBqENg6nqSYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[: train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_labels_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za441egSoCAL",
        "outputId": "a7b111ac-deda-47f9-ced8-4af83ebd828e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of each label in the updated training data subset\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKpcdihUo84J",
        "outputId": "8147a8ee-32a7-40cc-f941-32f6d3b17aad"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To recreate a model the same as a previous model you've created you\n",
        "can uyse the `tf.keras.models.clone_model()` method, see more here https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model"
      ],
      "metadata": {
        "id": "dqe1jh-RhXq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build a model the same as model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"])\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJb_whBZgpxA",
        "outputId": "b8516034-ed7e-4b96-9419-7a0e6fd705da"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent, \n",
        "                train_labels_10_percent,\n",
        "                epochs=5,\n",
        "                validation_data=(val_sentences,val_labels),\n",
        "                callbacks=[create_tensorboard_callback(SAVE_DIR,\"tf_hub_sentence_encoder_10_percent_correct_split\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrPzAX-FimZj",
        "outputId": "609afc7e-1d55-49b8-a4d0-dc6965e3890e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20230216-013254\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 36ms/step - loss: 0.6658 - accuracy: 0.7066 - val_loss: 0.6419 - val_accuracy: 0.7375\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.5914 - accuracy: 0.8131 - val_loss: 0.5783 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.5142 - accuracy: 0.8088 - val_loss: 0.5253 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.4556 - accuracy: 0.8175 - val_loss: 0.4962 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.4164 - accuracy: 0.8350 - val_loss: 0.4833 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDnlBjabj2dJ",
        "outputId": "d7bb395a-d728-40a4-de7f-9ffb72c01a78"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19831352],\n",
              "       [0.62198055],\n",
              "       [0.9401872 ],\n",
              "       [0.34448436],\n",
              "       [0.55145496],\n",
              "       [0.73335284],\n",
              "       [0.9075215 ],\n",
              "       [0.8348709 ],\n",
              "       [0.86431724],\n",
              "       [0.16901174]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3WKNSAOkOlE",
        "outputId": "04b72b8b-f6da-4b60-85bc-9d4ef8f95f15"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                   y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ6yFgmRkflX",
        "outputId": "fa8b26d5-e3a3-45a7-d54a-309d30f1c3ea"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'precision': 0.7782520175632252,\n",
              " 'recall': 0.7782152230971129,\n",
              " 'f1': 0.7772416104347588}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKv_UIxnk2_V",
        "outputId": "7180d93d-435c-462a-85ff-fbd0e41140bf"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8135161424410383,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.8111730155404432}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the performance of each of ou models"
      ],
      "metadata": {
        "id": "UexVhq5jr2hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                  \"1_simple_dense\": model_1_results,\n",
        "                  \"2_lstm\": model_2_results,\n",
        "                  \"3_gru\": model_3_results,\n",
        "                  \"4_bidirectional\": model_4_results,\n",
        "                  \"5_conv1d\": model_5_results,\n",
        "                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()"
      ],
      "metadata": {
        "id": "UyeHdHrflG3R"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "89LMKc6dsN-0",
        "outputId": "a6f79ba2-67b9-4be8-aeb5-155d253d2d19"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 accuracy  precision    recall        f1\n",
              "baseline                         0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   0.782152   0.787727  0.782152  0.778783\n",
              "2_lstm                           0.771654   0.779129  0.771654  0.767257\n",
              "3_gru                            0.771654   0.773050  0.771654  0.769710\n",
              "4_bidirectional                  0.761155   0.761263  0.761155  0.759843\n",
              "5_conv1d                         0.751969   0.753207  0.751969  0.749649\n",
              "6_tf_hub_use_encoder             0.812336   0.813516  0.812336  0.811173\n",
              "7_tf_hub_use_encoder_10_percent  0.778215   0.778252  0.778215  0.777242"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b491a5b-1632-4d53-bdc3-587807fd56d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.787727</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.778783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.779129</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.767257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.773050</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.769710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.761155</td>\n",
              "      <td>0.761263</td>\n",
              "      <td>0.761155</td>\n",
              "      <td>0.759843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.751969</td>\n",
              "      <td>0.753207</td>\n",
              "      <td>0.751969</td>\n",
              "      <td>0.749649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.813516</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.811173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.778252</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.777242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b491a5b-1632-4d53-bdc3-587807fd56d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b491a5b-1632-4d53-bdc3-587807fd56d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b491a5b-1632-4d53-bdc3-587807fd56d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "6q5_d6ABtfb0",
        "outputId": "eddfa46f-b62e-4417-cea4-42fdeb396e93"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f74484cd1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "2j_7Hpxdt2XN",
        "outputId": "e57d8e91-3d5a-48c7-bbf6-f7ed4941a462"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74482bd550>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## uploading our model training logs to TensorBoard.dev\n",
        "https://tensorboard.dev/"
      ],
      "metadata": {
        "id": "wqQGfRg6vSMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View TensorBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
        "# Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP modelling Experiments ZEM TF Course Video\" \\\n",
        "  --description \"Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset\" \\\n",
        "  --one_shot # exit the uploader once uploading is finished"
      ],
      "metadata": {
        "id": "gfCRReHiuu1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I've ran the cell above, my modelling experiments are visable on TensorBoard.dev\n",
        "> **Resource:** TensorBoard is great for quickly tracking experiments\n",
        "but for quickly tracking experiments but for larger sacle experiments\n",
        "and a whole bunch more tracking options, check out Weights & Biases:\n",
        "https://wandb.ai/site"
      ],
      "metadata": {
        "id": "TWGmXf-c4Ope"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See the previous TensorBoard Dev experiments you've run ...\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "id": "Ybut99q55U7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
        "!tensorboard dev delete --experiment_id {experiment_id}"
      ],
      "metadata": {
        "id": "8jm2qJqW1icC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading a trainer model\n",
        "\n",
        "There are two main formats to save a model to in TensorFlow:\n",
        "1. The HDF5 format\n",
        "2. The `SaveModel` format (this is the default when using Tensorflow)"
      ],
      "metadata": {
        "id": "q4K7OTHZ7m4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "SEUgIJ_L7fU3"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom Hub Layer (required HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", custom_objects={\"KerasLayer\":hub.KerasLayer})"
      ],
      "metadata": {
        "id": "Uzum9InQ794Q"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0OwxH468yQI",
        "outputId": "00a323d9-fdc5-4601-8662-ea19e0c8cce4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 15ms/step - loss: 0.4288 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4288128614425659, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's save to the `SaveModel` format... (see more on this here: https://www.tensorflow.org/tutorials/keras/save_and_load?hl=zh-cn)"
      ],
      "metadata": {
        "id": "VlpwA0y19Ti_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoer model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SaveModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fuedY5J8_x_",
        "outputId": "14fdc20a-845b-4ba2-c32f-fcda4336276a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a d model from the SaveModel format\n",
        "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SaveModel_format\")"
      ],
      "metadata": {
        "id": "lmTb5-VN9g3I"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model in SavedModel format\n",
        "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzo5aRS9-R-b",
        "outputId": "ac35ec91-6359-4b13-ae6a-28a72e3596c0"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4288 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4288128614425659, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* And of thee wrong examples which ones is it getting *most* wrong (thos will prediction probabilities closest to the opposite class)\n",
        "\n",
        "For exampl if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice vera.\n",
        "\n"
      ],
      "metadata": {
        "id": "4B2pTAj6_Edv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pretrained model from Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KRK9CcYAHUh",
        "outputId": "7f3a819a-4369-4ce6-95d0-a27c25e72cfe"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-16 02:15:10--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.16.128, 172.253.62.128, 172.253.63.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.16.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   180MB/s    in 4.9s    \n",
            "\n",
            "2023-02-16 02:15:15 (186 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMASWCeoAiDm",
        "outputId": "407fc7ac-b557-490c-ccc8-2d1f546b4062"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 8ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_pred = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXUMSOJvA3R_",
        "outputId": "16e8cb24-8c22-46d9-f2b0-5d3add665aa0"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best performing model predictions labels + probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "             \"target\": val_labels,\n",
        "             \"pred\": model_6_pretrained_pred,\n",
        "             \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b9XeojSI-NX7",
        "outputId": "75ef747d-6ce2-461d-cce1-691f33bc2aff"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29eb0b41-e662-4f41-a0e1-1db65492f456\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29eb0b41-e662-4f41-a0e1-1db65492f456')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29eb0b41-e662-4f41-a0e1-1db65492f456 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29eb0b41-e662-4f41-a0e1-1db65492f456');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values((\"pred_prob\"), ascending=False)\n",
        "most_wrong[:10] # these are false positives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6Ew-YVn7BpRj",
        "outputId": "000f5d1a-a342-4cf6-fe97-7b80d23d8923"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   \n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "31    0.910196  \n",
              "759   0.876982  \n",
              "628   0.852300  \n",
              "209   0.835455  \n",
              "251   0.827213  \n",
              "393   0.814816  \n",
              "109   0.810840  \n",
              "49    0.803122  \n",
              "119   0.766901  \n",
              "344   0.766625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a12efb9-8d8d-4a37-82f9-d23c3d4f3fd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a12efb9-8d8d-4a37-82f9-d23c3d4f3fd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a12efb9-8d8d-4a37-82f9-d23c3d4f3fd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a12efb9-8d8d-4a37-82f9-d23c3d4f3fd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's remind ourselves of the target labels\n",
        "\n",
        "* `0` = not disaster\n",
        "* `1` = disaster"
      ],
      "metadata": {
        "id": "uaQ5pIeOC0vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong.tail() # these are false negative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Br7sSC4pCSlj",
        "outputId": "2402d5c9-8d6e-4f25-be4d-9db3c4fd1019"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
              "233                    I get to smoke my shit in peace       1   0.0   \n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
              "\n",
              "     pred_prob  \n",
              "411   0.043918  \n",
              "233   0.042087  \n",
              "38    0.038998  \n",
              "244   0.038949  \n",
              "23    0.037186  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9846677-ce9b-4b3b-83cc-7b88825ed8ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9846677-ce9b-4b3b-83cc-7b88825ed8ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9846677-ce9b-4b3b-83cc-7b88825ed8ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9846677-ce9b-4b3b-83cc-7b88825ed8ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _,text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iP3WEffDft1",
        "outputId": "56f7cd17-91cb-475b-a472-7b3f59d4894d"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957082748413\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769820928573608\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523001074790955\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354545831680298\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272131681442261\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8148159384727478\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108397126197815\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8031217455863953\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669006586074829\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7666250467300415\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false negative (model predicted 0 when should've been 1)\n",
        "for row in most_wrong[:-10].itertuples():\n",
        "  _,text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk_76d3cE8Jn",
        "outputId": "86002b5b-0b4f-451d-b607-61fe18c3ef27"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957082748413\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769820928573608\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523001074790955\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354545831680298\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272131681442261\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8148159384727478\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108397126197815\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8031217455863953\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669006586074829\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7666250467300415\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7626621723175049\n",
            "Text:\n",
            "The Sound of Arson\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7472231388092041\n",
            "Text:\n",
            "Deaths 3 http://t.co/nApviyGKYK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7471619844436646\n",
            "Text:\n",
            "FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7424100637435913\n",
            "Text:\n",
            "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7399969100952148\n",
            "Text:\n",
            "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7380801439285278\n",
            "Text:\n",
            "The #tubestrike is because TFL workers may have trouble planning downtime. I hope none need emergency services. http://t.co/iCSFDSiFqb\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7356606721878052\n",
            "Text:\n",
            "@BrodyFrieling @hanna_brooksie photo bombed\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.716756284236908\n",
            "Text:\n",
            "GENERAL AUDIENCE: On Wounded Families | ZENIT - The World Seen From Rome http://t.co/hFvnyfT78C\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7162532210350037\n",
            "Text:\n",
            "Day 2. Liquidation of emergency at chemical object. #USAR2015 #USAR15 #RUOR #??????????? http://t.co/gGTmDqUdDo\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7122594714164734\n",
            "Text:\n",
            "@RebeccaforReal accepts Wisconsin Emergency Response Plan on behalf of @GovWalker #nbc15 http://t.co/Pis0aiVRbR\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7117387056350708\n",
            "Text:\n",
            "@pxnatosil @RenuncieDilma  Fatality!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6949765086174011\n",
            "Text:\n",
            "Trafford Centre film fans angry after Odeon cinema evacuated following false fire alarm   http://t.co/6GLDwx71DA\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6924801468849182\n",
            "Text:\n",
            "Article by Michael Jackman at Metro Times Detroit:\n",
            "The group later downgraded the estimate to 37 square miles of... http://t.co/h31mmuduqt\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6918948888778687\n",
            "Text:\n",
            ".@AIGinsurance CEO: Divestitures and #Catastrophe Losses Temper Q2 #Results http://t.co/2y2wZk1FrM\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6880071759223938\n",
            "Text:\n",
            "My phone looks like it was in a car ship airplane accident. Terrible\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6571958065032959\n",
            "Text:\n",
            "Love is the weapon for this wounded generation &lt;3\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6566486358642578\n",
            "Text:\n",
            "Cyclists it is pandemonium on the roads today. Drive carefully!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6561861634254456\n",
            "Text:\n",
            "the windstorm blew thru my open window and now my bong is in pieces just another example of nature's indifference to human suffering\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6449202299118042\n",
            "Text:\n",
            "Haley Lu Richardson Fights for Water in The Last Survivors (Review) http://t.co/oObSCFOKtQ\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6337713599205017\n",
            "Text:\n",
            "Photo: postapocalypticflimflam: Prodding around the rubble. http://t.co/Bgy4i47j70\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6278931498527527\n",
            "Text:\n",
            "@cjbanning 4sake of argsuppose pre-born has attained individl rights.Generally courtof law forbids killing unless dead person did something\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6268866658210754\n",
            "Text:\n",
            "Diageo's CEO stresses that a board revolt at United Spirits has not impacted Indian operations http://t.co/STPOdA901U\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6126309633255005\n",
            "Text:\n",
            "Crack in the path where I wiped out this morning during beach run. Surface wounds on left elbow and right knee. http://t.co/yaqRSximph\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.6044843792915344\n",
            "Text:\n",
            "Do you have a plan? Emergency Preparedness for #Families of\n",
            "Children with Special Needs  http://t.co/RdOVqaUAx5  #autism #specialneeds\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5865288972854614\n",
            "Text:\n",
            "@RedCoatJackpot *As it was typical for them their bullets collided and none managed to reach their targets; such was the ''curse'' of a --\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.579813539981842\n",
            "Text:\n",
            "there's this person &amp; they reckon when you're dying your brain floods with dmt causing you to relive your life in real time in a simulation\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5744490027427673\n",
            "Text:\n",
            "He made such a good point. White person comings mass murder labelled as criminal minority does the same thing... http://t.co/37qPsSnaCv\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5735116600990295\n",
            "Text:\n",
            "Emergency Response and Hazardous Chemical Management: Principles and Practices http://t.co/4sSuyhkgRB http://t.co/TDerBtgZ2k\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5689481496810913\n",
            "Text:\n",
            "Came across this fire video not mine..enjoy..Babes way of saying hi to me while he's in the fire truck??\n",
            "#fireman #Û_ http://t.co/V5gTUnwohy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5630192756652832\n",
            "Text:\n",
            "Public Hearing on 2015-16 @SUNY_Orange budget Thurs 8/6 at 3:15 Emergency Services Ctr Goshen. http://t.co/80DzgCo6Vc\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5628424882888794\n",
            "Text:\n",
            "#helpme what do I do? My friend has been ticketed by Police in Wayne County Michigan into never- sending poverty cycle. How do I help him?\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5570700168609619\n",
            "Text:\n",
            "Ignition Knock (Detonation) Sensor Connector-Connecto MOTORCRAFT WPT-410 http://t.co/bSmJ2HVgwD http://t.co/bXalnEdy49\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5384086966514587\n",
            "Text:\n",
            "@Azimel 'Screaming Mad Scientist deceased after tumbling over heels and falling into sinkhole during investigation'\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5279858708381653\n",
            "Text:\n",
            "@nagel_ashley @Vicken52 @BasedLaRock @goonc1ty rip the world... its burning\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5257343649864197\n",
            "Text:\n",
            "@LegacyOfTheSith @SagaciousSaber @Lordofbetrayal Moved in a crescent formation small trails of dust left in their wake as they moved.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5202777981758118\n",
            "Text:\n",
            "WPRI 12 Eyewitness News Rhode Island set to modernize its voting equipment WPRI 12 EyewitnessÛ_ http://t.co/aP9JBrPmQg\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5095019936561584\n",
            "Text:\n",
            "Aftershock ã¢ (2010) Fullã¢ Streaming - YouTube http://t.co/vVE3UsesGf\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.5092296600341797\n",
            "Text:\n",
            "Russian #ushanka #winter #military fur hat (xl61-62) with soviet badge LINK:\n",
            "http://t.co/74YFQxvAK0 http://t.co/KXrEHVt6hL\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.50434410572052\n",
            "Text:\n",
            "The Five Fatal Flaws in the Iran Deal https://t.co/ztfEAd8GId via @YouTube\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.4978567361831665\n",
            "Text:\n",
            "@Dirk_NoMissSki yea but if someone faints why are they panicking?.. thats basic stuff ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.4950205385684967\n",
            "Text:\n",
            "Back from Seattle Tacoma and Portland. Whirlwind! http://t.co/qwHINBni8e\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.49278557300567627\n",
            "Text:\n",
            "#computers #gadgets Two giant cranes holding a bridge collapse into nearby homes http://t.co/UZIWgZRynY #slingnews\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.49255263805389404\n",
            "Text:\n",
            "I moved to England five years ago today. What a whirlwind of time it has been! http://t.co/eaSlGeA1B7\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.49134406447410583\n",
            "Text:\n",
            "China's Stock Market Crash: Are There Gems In The Rubble? http://t.co/BqBLWiw08g #ROIMentor #yycwalks\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.46357131004333496\n",
            "Text:\n",
            "Medieval airplane hijacker testa: earnings the distinction divers: HtaRvrGLY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.45674192905426025\n",
            "Text:\n",
            "DireTube Information ÛÒ Egypt Cyprus and Greece agreed to fightåÊterrorism http://t.co/V6IjxCCD2I http://t.co/YSXhFWMGOD\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.4498384892940521\n",
            "Text:\n",
            "US wont upgrade its infrastructure? http://t.co/NGEHhG9YGa' it a bad situation and its going to get ugly very quickly #USA #sustainability\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.43872562050819397\n",
            "Text:\n",
            "A Dayton-area org tells me it was hit by a cyber attack: http://t.co/7LhKJz0IVO\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.4106840491294861\n",
            "Text:\n",
            "133 N past  the 5 L lane is reopened. All other lanes are closed. All lanes are open on the 133 S. Trash truck fire cleanup. @KNX1070\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.4041580557823181\n",
            "Text:\n",
            "Nearly had a heart attack just now; loud bang against window next to meÛ_turns out it was two birds flying into the glass.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3958093225955963\n",
            "Text:\n",
            "#World #News Qld police wrap Billy Gordon investigation: QUEENSLAND Police have wrapped up their investigation...  http://t.co/msgnNDxOeK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.39491426944732666\n",
            "Text:\n",
            "When ur friend and u are talking about forest fires in a forest and he tells u to drop ur mix tape out there... #straightfire\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.391987144947052\n",
            "Text:\n",
            "I never knew about the relationship btwn Kansas City Hyatt bridge collapse &amp; AIA's COTE.   http://t.co/ThS9IqSWP3 via @HuffPostArts\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.38917964696884155\n",
            "Text:\n",
            "@DavidJordan88 @Stephanenny Except we don't know who started the riot or if it even makes sense to credit any particular individuals...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3880815804004669\n",
            "Text:\n",
            "There's a weird siren going off here...I hope Hunterston isn't in the process of blowing itself to smithereens...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.38723471760749817\n",
            "Text:\n",
            "#ClimateChange Eyewitness to Extreme Weather: 11 Social Media Posts that Show Just How Crazy Things A... http://t.co/czpDn9oBiT #Anarchy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3847241699695587\n",
            "Text:\n",
            "#Metepec #Mexico - ?NIGHT DISASTER?...E(Oficial) @ #NitClub #mÌ¼sica #mÌ¼sica http://t.co/WTfJF9jjzs\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3820633590221405\n",
            "Text:\n",
            "RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3810732662677765\n",
            "Text:\n",
            "So this storm just came out of no where. .fuck me its cool\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.37615373730659485\n",
            "Text:\n",
            "Breakfast links: Work from home: Derailed: An empty train derailed at Smithsonian this morning suspending ser... http://t.co/iD4QGqDnJQ\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3712228238582611\n",
            "Text:\n",
            "Oops: Bounty hunters try to raid Phoenix police chief's home: http://t.co/yPRJWMigHL -- A group of armed bounty... http://t.co/3RrKRCjYW7\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.36463305354118347\n",
            "Text:\n",
            "@emmerdale can we have a public vote for the next annual village disaster?  i want an isis strike or a nuclear accident &amp; end this forever\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.36174002289772034\n",
            "Text:\n",
            "@ColdMpress You up to commiting mass murder tonight?\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.34605368971824646\n",
            "Text:\n",
            "Savings and sewing in Guatemala: Savings and sewing in Guatemala. When a natural disaster hit seamstress Elvia...  http://t.co/jdx9OX2kIk\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.34354183077812195\n",
            "Text:\n",
            "Toddler drowned in bath after mum left room to fetch his pyjamas http://t.co/k9aSKtwXfL\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3345523476600647\n",
            "Text:\n",
            "Hollywood Movie About Trapped Miners Released in Chile: 'The 33' Hollywood movie about trapped miners starring... http://t.co/tyyfG4qQvM\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.32017284631729126\n",
            "Text:\n",
            "Policyholders object to Clico rescue plan http://t.co/E4DvI9vUXZ http://t.co/JyCpf8iYhg\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.3073952794075012\n",
            "Text:\n",
            "Crazy Mom Threw Teen Daughter a NUDE Twister Sex Party According To Her Friend50 =&gt;http://t.co/Hy5Pbe12TM http://t.co/c1nJpLi5oR\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.30522438883781433\n",
            "Text:\n",
            "How is it one careless match can start a forest fire but it takes a whole box to start a campfire?\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.261262983083725\n",
            "Text:\n",
            "In Kalmikya Astrakhan Volgagrad and Dagestan there is already no food left for the locusts\n",
            "\n",
            "  http://t.co/79Fw9zWxtP via @TIMEWorld\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.26033514738082886\n",
            "Text:\n",
            "Owner of Chicago-Area Gay Bar Admits to Arson Scheme http://t.co/ZPxE3fMYNG #LGBT\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.25235921144485474\n",
            "Text:\n",
            "shit is hard to get over but sometimes the tragedy means it's over soulja..\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.2481275200843811\n",
            "Text:\n",
            "#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/cOMuiOk3mP #prebreak #best\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.24587403237819672\n",
            "Text:\n",
            "Another fake hate crime Lesbians burn their own house down. What else Is new :http://t.co/66oBQmxImb\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.24200861155986786\n",
            "Text:\n",
            "The date for the release of EP03 DESOLATION is set. Stay tuned for more info while we finalise the schedule. #alt #electro #rock #comingsoon\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.230147585272789\n",
            "Text:\n",
            "Would a paramedic really do that? Leave someone inside a building that's about to collapse/blow up? @HalloIkBenWill\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.2255600541830063\n",
            "Text:\n",
            "Two hours to get to a client meeting. Whirlwind of emotions with this #tubestrike\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.22306491434574127\n",
            "Text:\n",
            "First time getting into #gbbo2015 and physically gasped at the cake 'mudslide' incident already way too emotionally invested...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.21822313964366913\n",
            "Text:\n",
            "Plans by former First Lady and wife of ex-President Goodluck Jonathan Dame Patience Jonathan to hijack the All... http://t.co/HaShGQAFic\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.19622944295406342\n",
            "Text:\n",
            "@camilacabello97 Internally and externally screaming\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.193192258477211\n",
            "Text:\n",
            "Sadly before she could save humanity Ursula drowned in the drool of a protoshoggoth but at least she sort of died doing what she loved.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.19235986471176147\n",
            "Text:\n",
            "annihilating quarterstaff of annihilation\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.18886812031269073\n",
            "Text:\n",
            "How to prepare your #property for a #storm:\n",
            "\n",
            "http://t.co/KhYqQsi6My http://t.co/G6Vs3XEinb\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.18628442287445068\n",
            "Text:\n",
            "Just came back from camping and returned with a new song which gets recorded tomorrow. Can't wait! #Desolation #TheConspiracyTheory #NewEP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.184482142329216\n",
            "Text:\n",
            "when you don't know which way an ambulance is coming from &lt;&lt;\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.18259315192699432\n",
            "Text:\n",
            "Body shops inundated with cars dented by hail... Good news insurance pays... Bad news :  you are stuck with deductible !\n",
            "#wcvb\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.18098455667495728\n",
            "Text:\n",
            "Julian Knight - @SCVSupremeCourt dismisses mass murderer's attempt to increase prisoner pay. Challenged quantum of 5% increase 2013.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1805841475725174\n",
            "Text:\n",
            "CDC has a pretty cool list of all bioterrorism agents :3\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1740589588880539\n",
            "Text:\n",
            "Can't believe more people in their mid 20's don't have high blood pressure. Life is stressful. #DecisionsOnDecisions\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1733349710702896\n",
            "Text:\n",
            "Stupid women nearly collided into me today after she came out of a junction not looking. Still kept coming towards me till I beep my horn\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.17317034304141998\n",
            "Text:\n",
            "#download &amp; #watch Demolition Frog (2002) http://t.co/81nEizeknm #movie\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.17275018990039825\n",
            "Text:\n",
            "Indeed!! I am fully aware of that battle! I support you in that fight!!  https://t.co/MctJnZX4H8\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.17246340215206146\n",
            "Text:\n",
            "@dreamoforgonon @TeeEss not to hijack but as a bona fide cislady I can confirm this as true; incidental homosexuality =/= gay/bi for women.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.17010682821273804\n",
            "Text:\n",
            "World War II book LIGHTNING JOE An Autobiography by General J. Lawton Collins http://t.co/R4khEH7iaf http://t.co/qSZgJfUutu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1676202416419983\n",
            "Text:\n",
            "suddenly it's off &amp; on gloomy &amp; thunder so loud it shakes the windows? Not ever on the Bay Area. Miss me w/that lol http://t.co/x4eCGGvnSN\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.16570734977722168\n",
            "Text:\n",
            "@MichaelWestBiz standard damage control\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1549467295408249\n",
            "Text:\n",
            "When you go to a concert and someone screams in your ear... Does it look like I wanna loose my hearing anytime soon???\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1503564566373825\n",
            "Text:\n",
            "A quarter whirlwind. They don't see it coming.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.14835865795612335\n",
            "Text:\n",
            "@Habbo bring back games from the past. Snowstorm. Tic tac toe. Battleships. Fast food. Matchwood.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1193600669503212\n",
            "Text:\n",
            "Leitchfield KY:\n",
            "\n",
            " Bella Edward &amp; Rosalie need rescue/adoption/local foster home(s)/sponsorships.\n",
            "\n",
            " Trapped &amp;... http://t.co/Ajay0sNPlg\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.11672414094209671\n",
            "Text:\n",
            "So I pick myself off the ground and swam before I drowned. Hit the bottom so hard I bounced twice suffice this time around is different.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.11602186411619186\n",
            "Text:\n",
            "@GodOf_Mischief_ -of Loki's daggers she pulled it out and jammed it into Mina's thigh. When Mina screamed and grabbed at her leg sif-\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1144515797495842\n",
            "Text:\n",
            "The ol' meltdown victory for the Mets.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.11191648244857788\n",
            "Text:\n",
            "@cspanwj If 90BLKs&amp;8WHTs colluded 2 take WHT F @USAgov AUTH Hostage&amp;2 make her look BLK w/Bioterrorism&amp;use her lgl/org IDis ID still hers?\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.10821016877889633\n",
            "Text:\n",
            "Yelp Bolsters Health Care Reviews With Investigative Journalism: Sick and injured patients at a local ER are t... http://t.co/E8aEGOFDY2\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.1067856177687645\n",
            "Text:\n",
            "@SaintRobinho86 someone has to be at the bottom of every league. Tonight clearly demonstrated why the Lions are where they are - sunk!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.10654854774475098\n",
            "Text:\n",
            "Until my death I'll forever rep the Jets.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.10461503267288208\n",
            "Text:\n",
            "If I fall is men GOD @Praiz8 is d bomb well av always known dat since 2008 bigger u I pray sir\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.10175439715385437\n",
            "Text:\n",
            "I Will Survive by Gloria Gaynor (with Oktaviana Devi) ÛÓ https://t.co/HUkJZ1wT36\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.10133487731218338\n",
            "Text:\n",
            "I wanna set some shit on fire.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.09887673705816269\n",
            "Text:\n",
            "Rand Paul's Debate Strategy 'demolish Some other bad ideas out there or point out maybe that there are some em... http://t.co/qzdqRBr4Lh\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.09457097947597504\n",
            "Text:\n",
            "Perspectives on the Grateful Dead: Critical Writings (Contributions to the Study http://t.co/fmu0fnuMxf http://t.co/AgGRyhVXKr\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.09369733929634094\n",
            "Text:\n",
            "Petition | Heartless owner that whipped horse until it collapsed is told he can KEEP his animal! Act Now! http://t.co/87eFCBIczM\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.09234566986560822\n",
            "Text:\n",
            "@Zak_Bagans this is Sabrina my dad rescued her from some dude who kept her in a cage. We've had her since I was 4 http://t.co/1k2PhQcuW8\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.08252664655447006\n",
            "Text:\n",
            "New post from @darkreading http://t.co/8eIJDXApnp New SMB Relay Attack Steals User Credentials Over Internet\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.08042651414871216\n",
            "Text:\n",
            "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.07898200303316116\n",
            "Text:\n",
            "Next May I'll be free...from school from obligations like family.... Best of all that damn curfew...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.07138810306787491\n",
            "Text:\n",
            "@BoyInAHorsemask its a panda trapped in a dogs body\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.07125735282897949\n",
            "Text:\n",
            "@reriellechan HE WAS THE LICH KING'S FIRST CASUALTY BLOCK ME BACK I HATE YOU! http://t.co/0Gidg9U45J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.0696713924407959\n",
            "Text:\n",
            "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the test dataset"
      ],
      "metadata": {
        "id": "PTAsKK5GF6J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test datast and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob:{pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKAX7q77FbJh",
        "outputId": "98fb2483-871a-4c90-bc44-5797d26dd149"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 448ms/step\n",
            "Pred: 1, Prob:0.5024018883705139\n",
            "Text:\n",
            "MicrosoftÛªs Nokia acquisition was an even bigger disaster than we ever imagined https://t.co/4MneTInGXl\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Pred: 1, Prob:0.9758628010749817\n",
            "Text:\n",
            "#Children traumatised after the Nepal earthquake are educated on coping mechanisms.   http://t.co/UbwDBydK1a\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Pred: 1, Prob:0.6174471974372864\n",
            "Text:\n",
            ".@denisleary Not sure how these folks rush into burning buildings but I'm grateful they do. #TrueHeroes\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Pred: 0, Prob:0.43346625566482544\n",
            "Text:\n",
            "ThorCon: A Thorium Molten Salt Reactor System that can be built Now https://t.co/K90M1qoE9q #thorium #Auspol #climate #nuclearrcSA #nuclear\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Pred: 0, Prob:0.2843116521835327\n",
            "Text:\n",
            "@AlyssaSpencer28 remember when beau and i collided on the slip and slide and I died ??????\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Pred: 0, Prob:0.08563050627708435\n",
            "Text:\n",
            "Bo2 had by far the best competitive maps imo hope bo3 is the same #InVahnWeTrust\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Pred: 1, Prob:0.9409421682357788\n",
            "Text:\n",
            "New post: 'India Train Crash Kills Dozens' http://t.co/6OQaZmQa3L\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Pred: 1, Prob:0.8165794610977173\n",
            "Text:\n",
            "Standing in mountaintop field scented with wildflowers dust and distant forest fires smell of impending rain in the air.  #fieldworksmells\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Pred: 0, Prob:0.1086546927690506\n",
            "Text:\n",
            "I lava you\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Pred: 0, Prob:0.21595534682273865\n",
            "Text:\n",
            "Oh my days!!!! Thank God Cain has survived!!! ??#Emmerdale #SummerFate\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your challenge... predicting on Tweets from the wild\n",
        "Go to your favouurite Twitter account and copy one of their latest Tweets.\n",
        "\n",
        "Then pass that Tweet through our trained model.\n",
        "Is that Tweet disaster or not a disaster (according to the model)? Is the model right or wrong"
      ],
      "metadata": {
        "id": "ORI-mDphH7wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event = \"\"\"Rescuers saved a dog from the rubble in Turkey yesterday. It was so afraid to come out at first.\n",
        "\n",
        "So much grief and so many miracles happening after these horrible earthquakes.\"\"\"\n",
        "pred_prob = tf.squeeze(model_6_pretrained.predict([event])) # our model expects a list as input\n",
        "pred = tf.round(pred_prob)\n",
        "print(f\"Pred: {int(pred)}, Prob:{pred_prob}\")\n",
        "print(f\"Text:\\n{event}\\n\")\n",
        "print(\"-----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXyykSTjEaJu",
        "outputId": "4c1dda54-5fa1-4f81-f057-f21ffb2677a7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "Pred: 1, Prob:0.9639112949371338\n",
            "Text:\n",
            "Rescuers saved a dog from the rubble in Turkey yesterday. It was so afraid to come out at first.\n",
            "\n",
            "So much grief and so many miracles happening after these horrible earthquakes.\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff"
      ],
      "metadata": {
        "id": "J5Cp0opTI-3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI5IWVYnIh8B",
        "outputId": "a2f88ffe-a00e-4956-8762-54034b80cbfd"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8135161424410383,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.8111730155404432}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE3fkJhOJDfy",
        "outputId": "2df0d4f9-4440-4ca9-f769-2d55c366439c"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a function to measure the time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples)\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time =end_time-start_time # calculate how long predictions took to mak\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "5y1Bg6sLJGAy"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcHVgHFjJ-pe",
        "outputId": "64033bf5-5107-42d8-9376-fa413a7bc6a8"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2424294299999019, 0.00031814885826758784)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5bMlFnlKPe9",
        "outputId": "8bac12f4-b79f-4c0f-b240-f2fefa71c705"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.06323084799987555, 8.298011548540098e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gt results for pretrained GS model\n",
        "model_6_pretrained_results = calculate_results(y_true = val_labels,\n",
        "                        y_pred=model_6_pretrained_pred)\n",
        "model_6_pretrained_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cdvAKP4K17T",
        "outputId": "368ced11-c784-45fa-92fc-d46f779ff2af"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651,\n",
              " 'f1': 0.8148082644367335}"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label = \"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "A-PL_qutKqJ5",
        "outputId": "fdc9e75f-e536-4a3a-a159-1ac8e75106c8"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'F1-score')"
            ]
          },
          "metadata": {},
          "execution_count": 165
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQOXe8SSM1Ht"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}